{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Definition\n",
    "Dataset:\n",
    "The dataset used for this task is a simple binary classification dataset, represented by the \"OR problem.\" The input dataset consists of all possible combinations of binary values (0, 0), (0, 1), (1, 0), (1, 1), with corresponding output labels that represent the OR operation results. The output labels are binary (0 or 1).\n",
    "\n",
    "Task:\n",
    "The task is to train a neural network to predict the output of the OR operation. The model should learn the correct classification for each combination of inputs (X = [0, 0], [0, 1], [1, 0], [1, 1]) and produce the corresponding output (Y = [0], [1], [1], [1]). In the OR operation, the output is 1 if at least one of the inputs is 1, and 0 only when both inputs are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 0.1872569373156708\n",
      "Epoch 1000 - Loss: 0.13091205241705686\n",
      "Epoch 2000 - Loss: 0.048059258618477305\n",
      "Epoch 3000 - Loss: 0.017784068110331508\n",
      "Epoch 4000 - Loss: 0.009223223381770408\n",
      "Epoch 5000 - Loss: 0.005852448783419247\n",
      "Epoch 6000 - Loss: 0.004165096539805562\n",
      "Epoch 7000 - Loss: 0.0031829531234926728\n",
      "Epoch 8000 - Loss: 0.0025512737606144895\n",
      "Epoch 9000 - Loss: 0.002115524661126214\n",
      "\n",
      "Predictions after training:\n",
      "[[0.06696032]\n",
      " [0.96362056]\n",
      " [0.96311294]\n",
      " [0.99467589]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid Activation Function: Maps any input to a value between 0 or 1.\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of Sigmoid Activation Function: Used during backpropagation to calculate the gradient.\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Neural Network Class Definition\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size      # Number of input features\n",
    "        self.hidden_size = hidden_size    # Number of neurons in the hidden layer\n",
    "        self.output_size = output_size    # Number of output neurons\n",
    "\n",
    "        # Initialize weights and biases closer to zero\n",
    "        self.weights_input_hidden = np.array([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]])  # Input to hidden\n",
    "        self.bias_hidden = np.array([[0.1, 0.1, 0.1]])  # Hidden layer bias\n",
    "\n",
    "        self.weights_hidden_output = np.array([[0.2], [0.3], [0.4]])  # Hidden to output\n",
    "        self.bias_output = np.array([[0.1]])  # Output layer bias\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.input_layer = X    # Store the input data\n",
    "\n",
    "        # Calculate the input to the hidden layer and apply the activation function\n",
    "        self.hidden_layer_input = np.dot(self.input_layer, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.hidden_layer_output = sigmoid(self.hidden_layer_input)\n",
    "\n",
    "        # Calculate the input to the output layer and apply the activation function\n",
    "        self.output_layer_input = np.dot(self.hidden_layer_output, self.weights_hidden_output) + self.bias_output\n",
    "        self.output_layer_output = sigmoid(self.output_layer_input)\n",
    "\n",
    "        return self.output_layer_output\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        # Compute the error in the output layer\n",
    "        error_output = y - self.output_layer_output\n",
    "\n",
    "        # Calculate the gradient (delta) for the output layer\n",
    "        output_layer_delta = error_output * sigmoid_derivative(self.output_layer_output)\n",
    "\n",
    "        # Compute the error in the hidden layer\n",
    "        error_hidden = output_layer_delta.dot(self.weights_hidden_output.T)\n",
    "\n",
    "        # Calculate the gradient (delta) for the hidden layer\n",
    "        hidden_layer_delta = error_hidden * sigmoid_derivative(self.hidden_layer_output)\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.weights_hidden_output += self.hidden_layer_output.T.dot(output_layer_delta) * learning_rate\n",
    "        self.bias_output += np.sum(output_layer_delta, axis=0, keepdims=True) * learning_rate\n",
    "        self.weights_input_hidden += X.T.dot(hidden_layer_delta) * learning_rate\n",
    "        self.bias_hidden += np.sum(hidden_layer_delta, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            self.forward(X)   # Perform a forward pass\n",
    "            self.backward(X, y, learning_rate)     # Perform a backward pass (backpropagation)\n",
    "\n",
    "            # Print loss (mean squared error) every 1000 epochs\n",
    "            if epoch % 1000 == 0:\n",
    "                loss = np.mean(np.square(y - self.output_layer_output))\n",
    "                print(f\"Epoch {epoch} - Loss: {loss}\")\n",
    "\n",
    "# Main Program\n",
    "if __name__ == \"__main__\":\n",
    "    # OR Problem Dataset\n",
    "    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "    # Changed y values to represent OR operation: output is 1 if either input is 1\n",
    "    y = np.array([[0], [1], [1], [1]])\n",
    "\n",
    "    # Increased hidden layer size to 3 neurons\n",
    "    nn = NeuralNetwork(input_size=2, hidden_size=3, output_size=1)\n",
    "\n",
    "    # Train for 10,000 epochs with a smaller learning rate for better convergence\n",
    "    nn.train(X, y, epochs=10000, learning_rate=0.05)\n",
    "\n",
    "    print(\"\\nPredictions after training:\")\n",
    "    print(nn.forward(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
